
@article{mccauley_dielectron_2016,
	title = {Dielectron events for use in education and outreach},
	url = {http://opendata.cern.ch/record/304},
	doi = {10.7483/OPENDATA.CMS.PCSW.AHVG},
	abstract = {The CMS collaboration has approved the release of 100k dielectron events in the invariant mass range 2-110 GeV for use in outreach and education. This document contains the files for this release.},
	urldate = {2023-09-21},
	author = {McCauley, Thomas},
	year = {2016},
	note = {Publisher: CERN Open Data Portal},
}

@misc{noauthor_ultimate_nodate,
	title = {The {Ultimate} {Guide} to {Random} {Forest} {Regression}},
	url = {https://www.keboola.com/blog/random-forest-regression},
	abstract = {Random forest is one of the most widely used machine learning algorithms in real production settings.},
	urldate = {2023-09-22},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/CEERNJ5A/random-forest-regression.html:text/html},
}

@misc{noauthor_sklearnensemblerandomforestregressor_nodate,
	title = {sklearn.ensemble.{RandomForestRegressor}},
	url = {https://scikit-learn/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html},
	abstract = {Examples using sklearn.ensemble.RandomForestRegressor: Release Highlights for scikit-learn 0.24 Combine predictors using stacking Comparing Random Forests and Histogram Gradient Boosting models Com...},
	language = {en},
	urldate = {2023-09-22},
	journal = {scikit-learn},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/FCBEIFC7/sklearn.ensemble.RandomForestRegressor.html:text/html},
}

@misc{noauthor_how_nodate,
	title = {How does randomization in a random forest work?},
	url = {https://www.quora.com/How-does-randomization-in-a-random-forest-work/answer/Edwin-Chen-1},
	abstract = {Edwin Chen's answer: Suppose you're very indecisive, so whenever you want to watch a movie, you ask your friend Willow if she thinks you'll like it. In order to answer, Willow first needs to figure out what movies you like, so you give her a bunch of movies and tell her whether you liked each one...},
	language = {en},
	urldate = {2023-09-22},
	journal = {Quora},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/MKCZGDX7/Edwin-Chen-1.html:text/html},
}

@book{jung_machine_2022,
	address = {Singapore},
	series = {Machine {Learning}: {Foundations}, {Methodologies}, and {Applications}},
	title = {Machine {Learning}: {The} {Basics}},
	isbn = {9789811681929 9789811681936},
	shorttitle = {Machine {Learning}},
	url = {https://link.springer.com/10.1007/978-981-16-8193-6},
	language = {en},
	urldate = {2023-09-22},
	publisher = {Springer Nature},
	author = {Jung, Alexander},
	year = {2022},
	doi = {10.1007/978-981-16-8193-6},
	keywords = {Applied Statistics, Artificial Intelligence, Data Analysis, Deep Learning, Machine Learning, Modelling, Optimization, Signal Processing, Statistical Learning Theory},
	file = {Full Text PDF:/Users/clemensbandrock/Uni/Zotero/storage/9CD36LPH/Jung - 2022 - Machine Learning The Basics.pdf:application/pdf},
}

@techreport{chai_root_2014,
	type = {preprint},
	title = {Root mean square error ({RMSE}) or mean absolute error ({MAE})?},
	url = {https://gmd.copernicus.org/preprints/7/1525/2014/gmdd-7-1525-2014.pdf},
	abstract = {Abstract. Both the root mean square error (RMSE) and the mean absolute error (MAE) are regularly employed in model evaluation studies. Willmott and Matsuura (2005) have suggested that the RMSE is not a good indicator of average model performance and might be a misleading indicator of average error and thus the MAE would be a better metric for that purpose. Their paper has been widely cited and may have influenced many researchers in choosing MAE when presenting their model evaluation statistics. However, we contend that the proposed avoidance of RMSE and the use of MAE is not the solution to the problem. In this technical note, we demonstrate that the RMSE is not ambiguous in its meaning, contrary to what was claimed by Willmott et al. (2009). The RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian. In addition, we show that the RMSE satisfies the triangle inequality requirement for a distance metric.},
	language = {en},
	urldate = {2023-09-22},
	institution = {Numerical Methods},
	author = {Chai, T. and Draxler, R. R.},
	month = feb,
	year = {2014},
	doi = {10.5194/gmdd-7-1525-2014},
	file = {Chai and Draxler - 2014 - Root mean square error (RMSE) or mean absolute err.pdf:/Users/clemensbandrock/Uni/Zotero/storage/93QBP8KP/Chai and Draxler - 2014 - Root mean square error (RMSE) or mean absolute err.pdf:application/pdf},
}

@misc{noauthor_63_nodate,
	title = {6.3. {Preprocessing} data},
	url = {https://scikit-learn/stable/modules/preprocessing.html},
	abstract = {The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream esti...},
	language = {en},
	urldate = {2023-09-22},
	journal = {scikit-learn},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/J3M8LY9A/preprocessing.html:text/html},
}

@misc{noauthor_sklearnpreprocessingstandardscaler_nodate,
	title = {sklearn.preprocessing.{StandardScaler}},
	url = {https://scikit-learn/stable/modules/generated/sklearn.preprocessing.StandardScaler.html},
	abstract = {Examples using sklearn.preprocessing.StandardScaler: Release Highlights for scikit-learn 1.2 Release Highlights for scikit-learn 1.1 Release Highlights for scikit-learn 1.0 Release Highlights for s...},
	language = {en},
	urldate = {2023-09-22},
	journal = {scikit-learn},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/RIRNIIWN/sklearn.preprocessing.StandardScaler.html:text/html},
}

@misc{noauthor_sklearntreedecisiontreeregressor_nodate,
	title = {sklearn.tree.{DecisionTreeRegressor}},
	url = {https://scikit-learn/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html},
	abstract = {Examples using sklearn.tree.DecisionTreeRegressor: Release Highlights for scikit-learn 0.24 Release Highlights for scikit-learn 0.22 Decision Tree Regression Multi-output Decision Tree Regression D...},
	language = {en},
	urldate = {2023-09-22},
	journal = {scikit-learn},
	file = {Snapshot:/Users/clemensbandrock/Uni/Zotero/storage/V2TNXTIW/sklearn.tree.DecisionTreeRegressor.html:text/html},
}
@misc{cern-electron-collision-data,
  author = {Federico Soria√±o},
  title = {CERN Electron Collision Data},
  year = {2010},
  publisher = {Kaggle},
  howpublished = {\url{https://www.kaggle.com/datasets/fedesoriano/cern-electron-collision-data}}
}
@misc{scikit-learn-DecisionTreeRegressor,
  author = {{scikit-learn contributors}},
  title = {DecisionTreeRegressor},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html}},
  year = {2023}
}
@misc{scikit-learn-Preprocessing,
  author = {{scikit-learn contributors}},
  title = {Preprocessing},
  howpublished = {\url{https://scikit-learn.org/stable/modules/preprocessing.html}},
  year = {2023}
}

@misc{scikit-learn-RandomForestRegressor,
  author = {{scikit-learn contributors}},
  title = {RandomForestRegressor},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html}},
  year = {2023}
}

@misc{scikit-learn-GridSearchCV,
  author = {{scikit-learn contributors}},
  title = {GridSearchCV},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html}},
  year = {2023}
}

@misc{scikit-learn-MLPRegressor,
  author = {{scikit-learn contributors}},
  title = {MLPRegressor},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html}},
  year = {2023}
}


