{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T15:12:00.189037Z",
     "start_time": "2023-09-18T15:11:59.274654Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T15:14:06.959825Z",
     "start_time": "2023-09-18T15:14:06.775733Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('dielectron.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete null values\n",
    "df = df.dropna(axis=0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicates\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of mass\n",
    "plt.figure(figsize=(6,6))\n",
    "df.M.plot(kind='hist', bins=200, color='blue')\n",
    "plt.title('Distribution of M')\n",
    "plt.xlabel('M - mass')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect outliers for px1,px2,py1,py2,pz1,pz2 us boxplot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(3,2,1)\n",
    "sns.boxplot(x=df['px1 '])\n",
    "plt.subplot(3,2,2)\n",
    "sns.boxplot(x=df['px2'])\n",
    "plt.subplot(3,2,3)\n",
    "sns.boxplot(x=df['py1'])\n",
    "plt.subplot(3,2,4)\n",
    "sns.boxplot(x=df['py2'])\n",
    "plt.subplot(3,2,5)\n",
    "sns.boxplot(x=df['pz1'])\n",
    "plt.subplot(3,2,6)\n",
    "sns.boxplot(x=df['pz2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scatte plot between M and each feature\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(0, features.shape[1]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.scatter(features[:,i], labels, color='blue', s=1)\n",
    "    plt.xlabel(df.columns[i])\n",
    "    plt.ylabel('M')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a correlation matrix\n",
    "corr = df.corr()\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "sns.heatmap(corr, annot=True, cmap='RdYlGn',vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "features = df.drop(['M', 'pt1', 'pt2', 'E1', 'E2','Q1', 'Q2', 'phi1', 'phi2', 'eta1', 'eta2'], axis=1).to_numpy()\n",
    "labels = df.M.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test and validation sets\n",
    "X_train, X, y_train, y = train_test_split(features, labels, test_size=0.2,train_size=0.8)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X,y,test_size = 0.5,train_size =0.5)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "X_test_std = StandardScaler().fit_transform(X_test)\n",
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "X_val_std = StandardScaler().fit_transform(X_val)\n",
    "\n",
    "np.allclose(X_train.mean(axis=0), np.zeros(X_train.shape[1])),\\\n",
    "    np.allclose(X_train_std.mean(axis=0),np.zeros(X_train_std.shape[1])),\\\n",
    "        np.allclose(X_train.std(axis=0), np.ones(X_train.shape[1])),\\\n",
    "            np.allclose(X_train_std.std(axis=0), np.ones(X_train_std.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(\"feature importancy\", clf.feature_importances_)\n",
    "y_pred = clf.predict(X_train_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(\"training error\", rmse)\n",
    "y_pred = clf.predict(X_test_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"test error\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predicted and actual values\n",
    "figure = plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_pred.shape[0]), y_pred, c=\"red\")\n",
    "plt.scatter(range(y_pred.shape[0]), y_test, c=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distribution of predicted and actual values\n",
    "fig, axs = plt.subplots(1, 2, figsize = (15,5))\n",
    "axs[0].hist(y_pred, bins=100)\n",
    "axs[0].axvline(y_pred.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[1].hist(y_test, bins=100)\n",
    "axs[1].axvline(y_test.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.show()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.predict(X_train_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(rmse)\n",
    "y_pred = clf.predict(X_test_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Regression\n",
    "regr = MLPRegressor(max_iter=1000, learning_rate=\"adaptive\").fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(rmse)\n",
    "y_pred = regr.predict(X_test_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X_train_std, y_train)\n",
    "clf = LinearRegression(fit_intercept=False)\n",
    "clf.fit(X_poly, y_train)\n",
    "y_pred = clf.predict(X_poly)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(rmse)\n",
    "#y_pred = clf.predict(X_poly)\n",
    "#rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#rmse\n",
    "figure = plt.figure(figsize=(20,20))\n",
    "plt.scatter(range(y_pred.shape[0]), y_pred, c=\"red\")\n",
    "plt.scatter(range(y_train.shape[0]), y_train, c=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distribution of predicted and actual values\n",
    "fig, axs = plt.subplots(1, 2, figsize = (15,5))\n",
    "axs[0].hist(y_pred, bins=100)\n",
    "axs[0].axvline(y_pred.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[1].hist(y_test, bins=100)\n",
    "axs[1].axvline(y_test.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
